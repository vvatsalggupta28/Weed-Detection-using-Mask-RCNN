{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "import pdb\n",
    "import numpy as np\n",
    "import skimage\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from matplotlib import pyplot\n",
    "# class that defines and loads the weed dataset\n",
    "class WeedDataset(Dataset):\n",
    "\t# load the dataset definitions\n",
    "\tdef load_dataset(self, dataset_dir, is_train=True):\n",
    "\t\t# define two class\n",
    "\t\tself.add_class(\"dataset\", 1, \"crop\")\n",
    "\t\tself.add_class(\"dataset\", 2, \"weed\")\n",
    "\t\t# define data locations\n",
    "\t\timages_dir = dataset_dir + '/raw images/'\n",
    "\t\tannotations_dir = dataset_dir + '/annotations/'\n",
    "\t\t\n",
    "\t\t# find all images\n",
    "\t\tfor filename in listdir(images_dir):\n",
    "\t\t\t# extract image id\n",
    "\t\t\timage_id = filename[:-4]\n",
    "\t\t\t#print('IMAGE ID: ',image_id)\n",
    "\t\t\t# skip bad images\n",
    "\t\t\tif (image_id == '.ipynb_checkpo'):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images after 115 if we are building the train set\n",
    "\t\t\tif int(image_id) in [48,51,57,95]:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif is_train and int(image_id) >= 32279:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t# skip all images before 115 if we are building the test/val set\n",
    "\t\t\tif not is_train and int(image_id) < 32279:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\timg_path = images_dir + filename\n",
    "\t\t\tann_path = annotations_dir + image_id + '.xml'\n",
    "\t\t\t# add to dataset\n",
    "\t\t\tself.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path, class_ids = [0,1,2])\n",
    "\n",
    "\t# extract bounding boxes from an annotation file\n",
    "\tdef extract_boxes(self, filename):\n",
    "\t\t# load and parse the file\n",
    "\t\ttree = ElementTree.parse(filename)\n",
    "\t\t# get the root of the document\n",
    "\t\troot = tree.getroot()\n",
    "\t\t# extract each bounding box\n",
    "\t\tboxes = list()\n",
    "\t\t#for box in root.findall('.//bndbox'):\n",
    "\t\tfor box in root.findall('.//object'):\n",
    "\t\t\tname = box.find('name').text\n",
    "\t\t\txmin = int(box.find('./bndbox/xmin').text)\n",
    "\t\t\tymin = int(box.find('./bndbox/ymin').text)\n",
    "\t\t\txmax = int(box.find('./bndbox/xmax').text)\n",
    "\t\t\tymax = int(box.find('./bndbox/ymax').text)\n",
    "\t\t\t#coors = [xmin, ymin, xmax, ymax, name]\n",
    "\t\t\tcoors = [xmin, ymin, xmax, ymax, name]\n",
    "\t\t\tboxes.append(coors)\n",
    "\t\t# extract image dimensions\n",
    "\t\twidth = int(root.find('.//size/width').text)\n",
    "\t\theight = int(root.find('.//size/height').text)\n",
    "\t\treturn boxes, width, height\n",
    "\n",
    "\t# load the masks for an image\n",
    "\tdef load_mask(self, image_id):\n",
    "\t\t#pdb.set_trace()\n",
    "\t\t# get details of image\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\t# define box file location\n",
    "\t\tpath = info['annotation']\n",
    "\t\t# load XML\n",
    "\t\tboxes, w, h = self.extract_boxes(path)\n",
    "\t\t# create one array for all masks, each on a different channel\n",
    "\t\tmasks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\t\t# create masks\n",
    "\t\tclass_ids = list()\n",
    "\t\tfor i in range(len(boxes)):\n",
    "\t\t\tbox = boxes[i]\n",
    "\t\t\trow_s, row_e = box[1], box[3]\n",
    "\t\t\tcol_s, col_e = box[0], box[2]\n",
    "\t\t\tif (box[4] == 'crop'):\n",
    "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 2\n",
    "\t\t\t\tclass_ids.append(self.class_names.index('crop'))\n",
    "\t\t\telse:\n",
    "\t\t\t\tmasks[row_s:row_e, col_s:col_e, i] = 1\n",
    "\t\t\t\tclass_ids.append(self.class_names.index('weed'))\n",
    "\t\treturn masks, asarray(class_ids, dtype='int32')\n",
    "\t# load an image reference\n",
    "\tdef image_reference(self, image_id):\n",
    "\t\tinfo = self.image_info[image_id]\n",
    "\t\treturn info['path']\n",
    "\n",
    "# define a configuration for the model\n",
    "class PWeedConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = \"weed_cfg\"\n",
    "\t# number of classes (background + weed + crop)\n",
    "\tNUM_CLASSES = 1 + 2; GPU_COUNT = 1; IMAGES_PER_GPU = 1; IMAGE_MAX_DIM=1280; IMAGE_MIN_DIM=720\n",
    "    \n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "\tAPs = list()\n",
    "\tfor image_id in dataset.image_ids:\n",
    "\t\t# load image, bounding boxes and masks for the image id\n",
    "\t\tprint(image_id); image1 = dataset.load_image(image_id)\n",
    "\t\tmask, class_ids = dataset.load_mask(image_id)\n",
    "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "\t\t# convert pixel values (e.g. center)\n",
    "\t\tscaled_image = mold_image(image1, cfg)\n",
    "\t\t# convert image into one sample\n",
    "\t\tsample = expand_dims(scaled_image, 0)\n",
    "\t\t# make prediction\n",
    "\t\tyhat = model.detect(sample, verbose=0)\n",
    "\t\t# extract results for first sample\n",
    "\t\tr = yhat[0]\n",
    "\t\t# calculate statistics, including AP\n",
    "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\t\t# store\n",
    "\t\tAPs.append(AP)\n",
    "\t# calculate the mean AP across all images\n",
    "\tmAP = mean(APs)\n",
    "\treturn mAP\n",
    "\n",
    "# prepare train set\n",
    "train_set = WeedDataset()\n",
    "train_set.load_dataset('Ronin_OPEN_DB', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# prepare test/val set\n",
    "test_set = WeedDataset()\n",
    "test_set.load_dataset('Ronin_OPEN_DB', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "# prepare config\n",
    "config = PWeedConfig()\n",
    "config.display()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='./', config=config)\n",
    "# load weights and exclude the output layers\n",
    "model.load_weights('mask_rcnn_weed_cfg_0004.h5', by_name=True)\n",
    "# evaluate model on training dataset\n",
    "train_mAP = evaluate_model(train_set, model, config)\n",
    "print(\"Train mAP: %.3f\" % train_mAP)\n",
    "# evaluate model on test dataset\n",
    "test_mAP = evaluate_model(test_set, model, config)\n",
    "print(\"Test mAP: %.3f\" % test_mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
